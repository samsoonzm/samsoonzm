<!DOCTYPE html><html lang="en"><head><meta http-equiv="Content-Security-Policy" content="default-src 'self' 'unsafe-inline' 'unsafe-eval' data: blob: https://cdnjs.cloudflare.com https://cdn.jsdelivr.net https://code.jquery.com https://unpkg.com https://d3js.org https://threejs.org https://cdn.plot.ly https://stackpath.bootstrapcdn.com https://maps.googleapis.com https://cdn.tailwindcss.com https://ajax.googleapis.com https://kit.fontawesome.com https://cdn.datatables.net https://maxcdn.bootstrapcdn.com https://code.highcharts.com https://tako-static-assets-production.s3.amazonaws.com https://www.youtube.com https://fonts.googleapis.com https://fonts.gstatic.com https://pfst.cf2.poecdn.net https://puc.poecdn.net https://i.imgur.com https://wikimedia.org https://*.icons8.com https://*.giphy.com https://picsum.photos https://images.unsplash.com; frame-src 'self' https://www.youtube.com https://trytako.com; child-src 'self'; manifest-src 'self'; worker-src 'self'; upgrade-insecure-requests; block-all-mixed-content;">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>链式思维提示引发大型语言模型的推理能力</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }
        
        h1, h2, h3 {
            color: #2c3e50;
        }
        
        .translation-container {
            display: flex;
            margin-bottom: 30px;
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            overflow: hidden;
        }
        
        .english, .chinese {
            padding: 20px;
            width: 50%;
            position: relative;
        }
        
        .english {
            border-right: 1px solid #eee;
        }
        
        .chinese {
            background-color: #f9f9ff;
        }
        
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
        }
        
        .header {
            text-align: center;
            margin-bottom: 30px;
        }
        
        .subheader {
            font-style: italic;
            color: #666;
            text-align: center;
            margin-bottom: 30px;
        }
        
        .figure-caption {
            text-align: center;
            font-style: italic;
            margin-top: 10px;
            color: #666;
        }
        
        /* 新增的样式 */
        .en-segment, .zh-segment {
            padding: 2px 0;
            border-radius: 3px;
            transition: background-color 0.2s ease;
        }
        
        .highlight {
            background-color: #ffeb3b5c;
        }
        
        .active-highlight {
            background-color: #ffc10740;
        }
        
        /* 添加小工具提示 */
        .tooltip {
            position: fixed;
            background: #333;
            color: white;
            padding: 5px 10px;
            border-radius: 4px;
            font-size: 14px;
            pointer-events: none;
            opacity: 0;
            transition: opacity 0.2s;
            z-index: 1000;
            max-width: 300px;
        }
        
        @media (max-width: 768px) {
            .translation-container {
                flex-direction: column;
            }
            
            .english, .chinese {
                width: 100%;
            }
            
            .english {
                border-right: none;
                border-bottom: 1px solid #eee;
            }
        }
    </style>
</head>
<body>
    <div class="tooltip" id="tooltip"></div>
    
    <div class="header">
        <h1>链式思维提示引发大型语言模型的推理能力</h1>
        <h3>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</h3>
    </div>
    
    <div class="subheader">
        <p>Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le, Denny Zhou</p>
        <p>Google Research, Brain Team</p>
        <p>{jasonwei,dennyzhou}@google.com</p>
    </div>

    <div class="translation-container">
        <div class="english">
            <h2>Abstract</h2>
            <p><span class="en-segment" data-id="abstract-1">We explore how generating a chain of thought—a series of intermediate reasoning steps—significantly improves the ability of large language models to perform complex reasoning.</span> <span class="en-segment" data-id="abstract-2">In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain-of-thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting.</span></p>
            <p><span class="en-segment" data-id="abstract-3">Experiments on three large language models show that chain-of-thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks.</span> <span class="en-segment" data-id="abstract-4">The empirical gains can be striking. For instance, prompting a PaLM 540B with just eight chain-of-thought exemplars achieves state-of-the-art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.</span></p>
        </div>
        <div class="chinese">
            <h2>摘要</h2>
            <p><span class="zh-segment" data-id="abstract-1">我们探索了如何通过生成思维链（一系列中间推理步骤）显著提高大型语言模型执行复杂推理的能力。</span> <span class="zh-segment" data-id="abstract-2">特别是，我们展示了这种推理能力如何在足够大的语言模型中通过一种简单的方法自然地出现，这种方法称为链式思维提示，其中在提示中提供了几个链式思维示例作为范例。</span></p>
            <p><span class="zh-segment" data-id="abstract-3">对三个大型语言模型的实验表明，链式思维提示提高了在算术、常识和符号推理任务上的表现。</span> <span class="zh-segment" data-id="abstract-4">实证收益可能是惊人的。例如，仅用八个链式思维示例提示PaLM 540B模型就在GSM8K数学应用题基准测试中达到了最先进的准确率，甚至超过了带验证器的微调GPT-3。</span></p>
        </div>
    </div>

    <div style="text-align: center;">
        <img src="https://i.imgur.com/3v6QZs8.png" alt="Figure 1: Chain-of-thought prompting example">
        <p class="figure-caption">图1：链式思维提示使大型语言模型能够处理复杂的算术、常识和符号推理任务。链式思维推理过程以高亮显示。</p>
    </div>

    <div class="translation-container">
        <div class="english">
            <h2>1 Introduction</h2>
            <p><span class="en-segment" data-id="intro-1">The NLP landscape has recently been revolutionized by language models (Peters et al., 2018; Devlin et al., 2019; Brown et al., 2020, inter alia).</span> <span class="en-segment" data-id="intro-2">Scaling up the size of language models has been shown to confer a range of benefits, such as improved performance and sample efficiency (Kaplan et al., 2020; Brown et al., 2020, inter alia).</span> <span class="en-segment" data-id="intro-3">However, scaling up model size alone has not proved sufficient for achieving high performance on challenging tasks such as arithmetic, commonsense, and symbolic reasoning (Rae et al., 2021).</span></p>
            <p><span class="en-segment" data-id="intro-4">This work explores how the reasoning ability of large language models can be unlocked by a simple method motivated by two ideas.</span> <span class="en-segment" data-id="intro-5">First, techniques for arithmetic reasoning can benefit from generating natural language rationales that lead to the final answer.</span> <span class="en-segment" data-id="intro-6">Prior work has given models the ability to generate natural language intermediate steps by training from scratch (Ling et al., 2017) or finetuning a pretrained model (Cobbe et al., 2021), in addition to neuro-symbolic methods that use formal languages instead of natural language (Roy and Roth, 2015; Chiang and Chen, 2019; Amini et al., 2019; Chen et al., 2019).</span> <span class="en-segment" data-id="intro-7">Second, large language models offer the exciting prospect of in-context few-shot learning via prompting.</span> <span class="en-segment" data-id="intro-8">That is, instead of finetuning a separate language model checkpoint for each new task, one can simply "prompt" the model with a few input–output exemplars demonstrating the task.</span> <span class="en-segment" data-id="intro-9">Remarkably, this has been successful for a range of simple question-answering tasks (Brown et al., 2020).</span></p>
        </div>
        <div class="chinese">
            <h2>1 引言</h2>
            <p><span class="zh-segment" data-id="intro-1">自然语言处理领域最近被语言模型彻底改变（Peters等，2018；Devlin等，2019；Brown等，2020，等）。</span> <span class="zh-segment" data-id="intro-2">扩大语言模型的规模已被证明能带来一系列好处，如提高性能和样本效率（Kaplan等，2020；Brown等，2020，等）。</span> <span class="zh-segment" data-id="intro-3">然而，仅仅扩大模型规模并不足以在具有挑战性的任务（如算术、常识和符号推理）上取得高性能（Rae等，2021）。</span></p>
            <p><span class="zh-segment" data-id="intro-4">本研究探讨了如何通过一种受两个想法驱动的简单方法来释放大型语言模型的推理能力。</span> <span class="zh-segment" data-id="intro-5">首先，算术推理技术可以受益于生成自然语言理由，从而得出最终答案。</span> <span class="zh-segment" data-id="intro-6">先前的工作通过从头开始训练（Ling等，2017）或微调预训练模型（Cobbe等，2021）赋予模型生成自然语言中间步骤的能力，此外还有使用形式语言而非自然语言的神经符号方法（Roy和Roth，2015；Chiang和Chen，2019；Amini等，2019；Chen等，2019）。</span> <span class="zh-segment" data-id="intro-7">其次，大型语言模型通过提示提供了令人兴奋的上下文少样本学习前景。</span> <span class="zh-segment" data-id="intro-8">也就是说，不必为每个新任务微调单独的语言模型检查点，只需简单地使用几个输入-输出示例"提示"模型演示任务。</span> <span class="zh-segment" data-id="intro-9">值得注意的是，这在一系列简单的问答任务中已经取得了成功（Brown等，2020）。</span></p>
        </div>
    </div>

    <!-- 更多的翻译内容可以按照上面的格式继续添加 -->

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            // 获取所有的段落
            const enSegments = document.querySelectorAll('.en-segment');
            const zhSegments = document.querySelectorAll('.zh-segment');
            const tooltip = document.getElementById('tooltip');
            
            // 为每个英文段落添加事件监听器
            enSegments.forEach(segment => {
                segment.addEventListener('mouseenter', function() {
                    // 获取对应的中文段落
                    const id = this.getAttribute('data-id');
                    const zhSegment = document.querySelector(`.zh-segment[data-id="${id}"]`);
                    
                    if (zhSegment) {
                        // 高亮显示对应的中文段落
                        zhSegment.classList.add('active-highlight');
                        this.classList.add('highlight');
                        
                        // 滚动到中文段落的位置
                        zhSegment.scrollIntoView({ behavior: 'smooth', block: 'center' });
                    }
                });
                
                segment.addEventListener('mouseleave', function() {
                    // 移除高亮
                    const id = this.getAttribute('data-id');
                    const zhSegment = document.querySelector(`.zh-segment[data-id="${id}"]`);
                    
                    if (zhSegment) {
                        zhSegment.classList.remove('active-highlight');
                        this.classList.remove('highlight');
                    }
                });
            });
            
            // 为每个中文段落添加事件监听器
            zhSegments.forEach(segment => {
                segment.addEventListener('mouseenter', function() {
                    // 获取对应的英文段落
                    const id = this.getAttribute('data-id');
                    const enSegment = document.querySelector(`.en-segment[data-id="${id}"]`);
                    
                    if (enSegment) {
                        // 高亮显示对应的英文段落
                        enSegment.classList.add('active-highlight');
                        this.classList.add('highlight');
                        
                        // 滚动到英文段落的位置
                        enSegment.scrollIntoView({ behavior: 'smooth', block: 'center' });
                    }
                });
                
                segment.addEventListener('mouseleave', function() {
                    // 移除高亮
                    const id = this.getAttribute('data-id');
                    const enSegment = document.querySelector(`.en-segment[data-id="${id}"]`);
                    
                    if (enSegment) {
                        enSegment.classList.remove('active-highlight');
                        this.classList.remove('highlight');
                    }
                });
            });
            
            // 添加提示框功能
            document.addEventListener('mousemove', function(e) {
                tooltip.style.left = (e.pageX + 15) + 'px';
                tooltip.style.top = (e.pageY + 15) + 'px';
            });
            
            // 添加点击功能，点击一段文本会持续高亮，直到点击其他地方
            document.addEventListener('click', function(e) {
                // 移除所有持续高亮
                document.querySelectorAll('.persistent-highlight').forEach(el => {
                    el.classList.remove('persistent-highlight');
                });
                
                // 如果点击的是段落，添加持续高亮
                if (e.target.classList.contains('en-segment') || e.target.classList.contains('zh-segment')) {
                    const id = e.target.getAttribute('data-id');
                    const pair = document.querySelector(`.en-segment[data-id="${id}"], .zh-segment[data-id="${id}"]`);
                    
                    if (pair && pair !== e.target) {
                        pair.classList.add('persistent-highlight');
                        e.target.classList.add('persistent-highlight');
                    }
                }
            });
        });
    </script>


</body></html>